# Проверка различных алгоритмов и структур данных на производительность.
## В [данном](https://github.com/dkoleev/PerformanceTestingInUnity) репозитории примеры тестов в юнити.

Характеристики компьютера на котором производились замеры:
![](https://github.com/dkoleev/PerformanceTesting/blob/master/Content/Images/pc_characteristic.png)

## 1. Эксперементы с кэшем процессора.
### Как локальность данных влияет на производительность.
В данных примерах рассматривается пространственная локальность (также существует временная).
### Немного теории прежде чем мы рассмотрим примеры.
В [презентации](https://docs.google.com/presentation/d/1zKsVoWUkBRu50UW5VW505fWX-KwT3m5T3WY_SnTajcs/edit?usp=sharing) наглядно описано как устроена современная память и процессоры.
Итак, что нам нужно знать об устройстве компьютера для того чтобы писать оптимизированные программы:
+ Процессор чтобы начать вычисления не получает данные из памяти напрямую, а загружает данные из неё в свой кэш, а из кэша уже в регистры (если в кратце почему так - кэш реализован на основе технологии SRAM (быстро но дорого), основаня память на DRAM(медленно но дёшево)).
+ Кэш процессора обычно состоит из нескольких уровней кэша (на некоторых уровнях кэш разделсяется между ядрами). Чем выше уровень тем выше скорость получения данных из него и тем он меньшего размера.
+ Данные из основной памяти в кэш считываются не побайтово а чанками, размер которых обычно 64 байта (так называемые кэш линии)

#### Пример 1.
Имеется массив:
``` 
int[] arr = new int[64 * 1024 * 1024];
```
Два примера, в первом пробегаемся по каждому 16-му элементу, а во втором по каждому первому:
```
for (int i = 0; i < arr.Length; i += 16)
  arr[i] *= 3;
 
for (int i = 0; i < arr.Length; i++) 
  arr[i] *= 3;
  ```
  Можно предположить что первый цикл отработает быстрее, но как показывают замеры, оба цикла занимают практически одинаковое количество циклов процессора (замеры проведены с помощью программы [vTune](https://software.intel.com/en-us/vtune)).
  ![](https://github.com/dkoleev/PerformanceTesting/blob/master/Content/Images/result_1.png) 
  <br>
  Данный пример наглядно показывает, что основное время тратится не на вычисления, а на получение данных из памяти.
  <br>
  #### Пример 2.
  Имеется двумерный массив:
  ```
  protected static int[,] Matrix;
  ```
  В первом случае мы пробегаемся по строкам:
  ```
       public override void Run(int cicles)
        {
            for (int c = 0; c < cicles; c++)
            {
                var sum = 0;
                for (int i = 0; i < MaxSize; ++i)
                    for (int j = 0; j < MaxSize; ++j)
                        sum += Matrix[i, j];
            }
        }
 ```
 Во втором по столбцам:
 ```
  public override void Run(int cicles)
        {
            for (int c = 0; c < cicles; c++)
            {
                var sum = 0;
                for (int i = 0; i < MaxSize; ++i)
                    for (int j = 0; j < MaxSize; ++j)
                        sum += Matrix[j, i];
            }
        }
```
Результат при пробеге по строкам:
<br>
![](https://github.com/dkoleev/PerformanceTesting/blob/master/Content/Images/res_2.png)
<br>
Результат при пробеге по столбацам:
<br>
![](https://github.com/dkoleev/PerformanceTesting/blob/master/Content/Images/res_column.png)
<br>
В данных замерах стоит обращать внимание только на показатель Memory Bound. Как мы видим при проходе по строкам производительность выше более чем в два раза. Также если посмотреть на графики мы увидим, что при проходе по столбцам в нашем случае самым узким местом является кэш третьего уровня 39,3% затем идет основная память 14,6%.
<br>
Почему именно кэш третьего уровня стал самым узким местом а не основная память? Потому что тот объём данных на котором производились замеры помещается в кэш третьего уровня. Поэтому также различие в скорости не столь разитильно, ведь доступ к кэшу третьего уровня намного быстрее чем к основной памяти.
<br>
Данный пример наглядно показывает насколько важно последтовательное расположение и чтение данных из памяти. Из-за того что данные из памяти и из одного уровня кэша в другой считываются не побайтово а кэш-линиями, при чтении данных столбцами кэши забиваются бесполезными данными, которые не учавствуют в вычислениях и соответсвенно быстрее забиваются, что приводит к необходимости чаще запрашивать данные из более медленной памяти.
<br>
![](https://github.com/dkoleev/PerformanceTesting/blob/master/Content/Images/row_column.png)
<br>
В конечном счёте всё сводится к одной простой мысли:
<br>
### Когда процессор выполняет чтение из памяти, он считывает целую строку кэша. Чем больше мы поместим в эту строку кэша полезных данных, тем большую скорость мы получим. Так что наша цель заключается в том, чтобы организовать структуры данных таким образом, чтобы обрабатываемые нами вещи находились в памяти одна за другой.


## Горячее холодное разделение (hot/cold splitting)
Даже в ситуации когда у нас данные находятся в линейном массиве данных и количество кэш-промахов минимально, у нас всё равно могут быть данные внутри сущности, которые мы используем крайне редко, но при этом они постоянно загружаются в кэш. В результате, каждая сущность увеличивается, а количество помещающихся в строку кэша сущностей уменьшается. Для решения этой проблемы существует метод холодного/горячего разделения.
Идея заключается в разделении данных на две части. Первая хранит "горячие" данные: состояния, которые мы используем на каждом кадре. Вторая хранит "холодные" данные: все остальное, что используется значительно реже.
Горячая часть - это основа объекта, тебе данные которые мы постоянно используем в логике и храним в самой сущности, чтобы избежать гонку указателей.
Холодная часть - то к чему мы обращаемся редко. Мы храним ссылку на ней в основной части, т.е. Связываем её с сущностью посредством композиции (пр. Паттерн Стратегия).
